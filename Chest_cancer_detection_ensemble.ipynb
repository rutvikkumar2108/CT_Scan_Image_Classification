{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Combining all the 4 models for ensemble Technique"
      ],
      "metadata": {
        "id": "v_IORpiZUSPd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF7oIF6uMx_p",
        "outputId": "84a05e4f-cb60-4c74-bf6a-dd038a0ccd51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: np_utils in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.10/dist-packages (from np_utils) (1.23.5)\n"
          ]
        }
      ],
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import keras\n",
        "from numpy import random\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, Activation\n",
        "from keras.layers import MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "! pip install np_utils\n",
        "from keras.applications import MobileNet, VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from sklearn.metrics import classification_report ,confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.utils import class_weight\n",
        "import seaborn as sns\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory of train, validation and test\n",
        "\n",
        "train_folder = \"/content/drive/MyDrive/Chect_data/train\"\n",
        "valid_folder = \"/content/drive/MyDrive/Chect_data/valid\"\n",
        "test_folder = \"/content/drive/MyDrive/Chect_data/test\""
      ],
      "metadata": {
        "id": "zPq-81zHnIYv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n\\t\\tTraining Set\")\n",
        "print(\"\\t  ========================\\n\")\n",
        "train_c = []\n",
        "for folder in os.listdir(train_folder):\n",
        "    train_c.append(folder)\n",
        "    print(\"\\nTrain \"+ folder + \" Class: \", len(os.listdir(train_folder + '/' + folder)))\n",
        "\n",
        "print(\"\\n\\n\", train_c)\n",
        "\n",
        "print(\"\\n\\n\\t\\tTesting Set\")\n",
        "print(\"\\t  ========================\\n\")\n",
        "test_c = []\n",
        "for folder in os.listdir(test_folder):\n",
        "    test_c.append(folder)\n",
        "    print(\"\\nTest \"+ folder + \" Class: \", len(os.listdir(test_folder + '/' + folder)))\n",
        "\n",
        "print(\"\\n\\n\", test_c)\n",
        "\n",
        "print(\"\\n\\n\\t\\tValidation Set\")\n",
        "print(\"\\t  ========================\\n\")\n",
        "val_c = []\n",
        "for folder in os.listdir(valid_folder):\n",
        "    val_c.append(folder)\n",
        "    print(\"\\nValidation \"+ folder + \" Class: \", len(os.listdir(valid_folder + '/' + folder)))\n",
        "\n",
        "print(\"\\n\\n\", val_c, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thobRJ76n9A6",
        "outputId": "73f2b395-98f1-4aca-923d-beb0e8391fc9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\t\tTraining Set\n",
            "\t  ========================\n",
            "\n",
            "\n",
            "Train normal Class:  148\n",
            "\n",
            "Train squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa Class:  155\n",
            "\n",
            "Train adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib Class:  195\n",
            "\n",
            "Train large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa Class:  115\n",
            "\n",
            "\n",
            " ['normal', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa', 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa']\n",
            "\n",
            "\n",
            "\t\tTesting Set\n",
            "\t  ========================\n",
            "\n",
            "\n",
            "Test squamous.cell.carcinoma Class:  90\n",
            "\n",
            "Test normal Class:  54\n",
            "\n",
            "Test adenocarcinoma Class:  120\n",
            "\n",
            "Test large.cell.carcinoma Class:  51\n",
            "\n",
            "\n",
            " ['squamous.cell.carcinoma', 'normal', 'adenocarcinoma', 'large.cell.carcinoma']\n",
            "\n",
            "\n",
            "\t\tValidation Set\n",
            "\t  ========================\n",
            "\n",
            "\n",
            "Validation normal Class:  13\n",
            "\n",
            "Validation squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa Class:  15\n",
            "\n",
            "Validation large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa Class:  21\n",
            "\n",
            "Validation adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib Class:  23\n",
            "\n",
            "\n",
            " ['normal', 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa', 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa', 'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224,224,3)\n",
        "num_class = 4\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")\n",
        "val_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "test_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_folder,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_folder,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle = False,\n",
        ")\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    valid_folder,\n",
        "    target_size=(224,224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olk9Bw4NoGST",
        "outputId": "6ad12540-182c-4ece-e1bd-e7c9b008f42f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 613 images belonging to 4 classes.\n",
            "Found 315 images belonging to 4 classes.\n",
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get list of class weights\n",
        "class_weights_list = class_weight.compute_class_weight(\n",
        "           class_weight='balanced',\n",
        "            classes=np.unique(train_generator.classes),\n",
        "            y=train_generator.classes)\n",
        "# Get class labels\n",
        "class_labels=np.unique(train_generator.classes)\n",
        "\n",
        "# Put weights in dict with class label\n",
        "class_weights = {}\n",
        "for class_i in range(len(class_labels)):\n",
        "     class_weights[class_labels[class_i]] = class_weights_list[class_i]\n",
        "\n",
        "# Check\n",
        "class_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ff-ziZhBpI5n",
        "outputId": "cc3e6dfd-e03e-4444-a9eb-71965b314b0a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.7858974358974359,\n",
              " 1: 1.3326086956521739,\n",
              " 2: 1.035472972972973,\n",
              " 3: 0.9887096774193549}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelling\n",
        "# 1. VGG16\n",
        "# 2. AlexNet\n",
        "# 3. InceptionV3\n"
      ],
      "metadata": {
        "id": "kNPTjLmiqc3G"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ALEXNET"
      ],
      "metadata": {
        "id": "XatncsOaCp28"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelVGG16 = VGG16(weights = 'imagenet',\n",
        "                     include_top = False,\n",
        "                     input_shape = input_shape)\n",
        "\n",
        "for layer in modelVGG16.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "5jQG_2NYpRKp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Sequential([\n",
        "    modelVGG16,\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size = (2,2)),\n",
        "    Dropout(.3),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(512, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(256, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(num_class, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "#print(model.summary())"
      ],
      "metadata": {
        "id": "74h2nbwQrpT9"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "opt1 = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
        "\n",
        "model1.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = opt,\n",
        "             metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "tc4P06EKsKSE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "model1.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#test = test_generator\n",
        "#score = model.evaluate(test, verbose = 1)\n",
        "#print(\"Test loss:\", score[0])\n",
        "#print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7-5oCJs0sQzK",
        "outputId": "aff777ce-934c-419e-c5e1-f0dce640b8db"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 23s 1s/step - loss: 2.2728 - accuracy: 0.3801 - val_loss: 1.6133 - val_accuracy: 0.4722\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 22s 1s/step - loss: 1.2937 - accuracy: 0.5400 - val_loss: 1.1166 - val_accuracy: 0.5278\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 1.1617 - accuracy: 0.5400 - val_loss: 0.7941 - val_accuracy: 0.5972\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.8702 - accuracy: 0.5775 - val_loss: 0.8801 - val_accuracy: 0.6250\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 12s 611ms/step - loss: 0.8627 - accuracy: 0.6248 - val_loss: 0.8420 - val_accuracy: 0.6389\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 12s 591ms/step - loss: 0.8288 - accuracy: 0.6509 - val_loss: 0.7309 - val_accuracy: 0.6667\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 15s 749ms/step - loss: 0.7252 - accuracy: 0.6754 - val_loss: 0.6149 - val_accuracy: 0.7361\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 13s 635ms/step - loss: 0.6214 - accuracy: 0.7227 - val_loss: 0.6295 - val_accuracy: 0.7917\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 12s 591ms/step - loss: 0.6286 - accuracy: 0.7227 - val_loss: 0.6125 - val_accuracy: 0.7778\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 12s 564ms/step - loss: 0.5608 - accuracy: 0.7651 - val_loss: 0.5344 - val_accuracy: 0.7917\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.5465 - accuracy: 0.7684 - val_loss: 0.5440 - val_accuracy: 0.7917\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.5927 - accuracy: 0.7406 - val_loss: 0.5595 - val_accuracy: 0.7500\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 12s 556ms/step - loss: 0.5356 - accuracy: 0.7537 - val_loss: 0.4686 - val_accuracy: 0.8056\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 12s 604ms/step - loss: 0.5183 - accuracy: 0.7879 - val_loss: 0.5511 - val_accuracy: 0.8056\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 13s 633ms/step - loss: 0.6132 - accuracy: 0.7520 - val_loss: 0.5137 - val_accuracy: 0.7917\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.4588 - accuracy: 0.8173 - val_loss: 0.4543 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.3891 - accuracy: 0.8206 - val_loss: 0.5195 - val_accuracy: 0.8472\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 0.4732 - accuracy: 0.8108 - val_loss: 0.4974 - val_accuracy: 0.8472\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 13s 662ms/step - loss: 0.4750 - accuracy: 0.8075 - val_loss: 0.5459 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 0.4601 - accuracy: 0.8075 - val_loss: 0.5315 - val_accuracy: 0.7778\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 13s 635ms/step - loss: 0.3920 - accuracy: 0.8287 - val_loss: 0.6394 - val_accuracy: 0.8056\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 13s 634ms/step - loss: 0.3967 - accuracy: 0.8206 - val_loss: 0.4688 - val_accuracy: 0.8333\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 14s 667ms/step - loss: 0.3686 - accuracy: 0.8548 - val_loss: 0.5883 - val_accuracy: 0.7917\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 12s 568ms/step - loss: 0.2609 - accuracy: 0.8989 - val_loss: 0.5635 - val_accuracy: 0.8750\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 0.3456 - accuracy: 0.8744 - val_loss: 0.4391 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 0.3872 - accuracy: 0.8418 - val_loss: 0.4075 - val_accuracy: 0.8611\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 0.3194 - accuracy: 0.8825 - val_loss: 0.4285 - val_accuracy: 0.8333\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 12s 570ms/step - loss: 0.3230 - accuracy: 0.8760 - val_loss: 0.4009 - val_accuracy: 0.8472\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 13s 614ms/step - loss: 0.3292 - accuracy: 0.8695 - val_loss: 0.3975 - val_accuracy: 0.8611\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 13s 649ms/step - loss: 0.2884 - accuracy: 0.8858 - val_loss: 0.4085 - val_accuracy: 0.8472\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 13s 643ms/step - loss: 0.3035 - accuracy: 0.8711 - val_loss: 0.3711 - val_accuracy: 0.8472\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 0.2878 - accuracy: 0.8858 - val_loss: 0.3962 - val_accuracy: 0.8194\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.2649 - accuracy: 0.8989 - val_loss: 0.5534 - val_accuracy: 0.7778\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 13s 637ms/step - loss: 0.2911 - accuracy: 0.8858 - val_loss: 0.3977 - val_accuracy: 0.8333\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 13s 634ms/step - loss: 0.2476 - accuracy: 0.9021 - val_loss: 0.4773 - val_accuracy: 0.8333\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 0.2268 - accuracy: 0.9038 - val_loss: 0.5779 - val_accuracy: 0.8611\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 13s 645ms/step - loss: 0.2092 - accuracy: 0.9152 - val_loss: 0.5324 - val_accuracy: 0.8472\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 0.2540 - accuracy: 0.8972 - val_loss: 0.6615 - val_accuracy: 0.8194\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 15s 740ms/step - loss: 0.3176 - accuracy: 0.8842 - val_loss: 0.5094 - val_accuracy: 0.8194\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.2561 - accuracy: 0.8858 - val_loss: 0.4319 - val_accuracy: 0.8889\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 13s 610ms/step - loss: 0.2192 - accuracy: 0.9119 - val_loss: 0.5317 - val_accuracy: 0.8889\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 13s 646ms/step - loss: 0.2935 - accuracy: 0.8679 - val_loss: 0.4061 - val_accuracy: 0.8750\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 13s 651ms/step - loss: 0.2467 - accuracy: 0.8956 - val_loss: 0.5543 - val_accuracy: 0.8750\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 0.2761 - accuracy: 0.9005 - val_loss: 0.5256 - val_accuracy: 0.8611\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 13s 633ms/step - loss: 0.2667 - accuracy: 0.8989 - val_loss: 0.3353 - val_accuracy: 0.9028\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 13s 631ms/step - loss: 0.2511 - accuracy: 0.8940 - val_loss: 0.4304 - val_accuracy: 0.8611\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.2295 - accuracy: 0.9201 - val_loss: 0.4303 - val_accuracy: 0.8611\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 13s 638ms/step - loss: 0.2737 - accuracy: 0.8891 - val_loss: 0.4389 - val_accuracy: 0.8889\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 0.2177 - accuracy: 0.9184 - val_loss: 0.3571 - val_accuracy: 0.9167\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 12s 602ms/step - loss: 0.2499 - accuracy: 0.9086 - val_loss: 0.3520 - val_accuracy: 0.8889\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-8286ecd2e0aa>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = len(test_generator)\n",
        "num_classes = len(test_generator.class_indices)\n",
        "\n",
        "predicted_probabilities_vgg16 = model1.predict(test_generator, steps=num_test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ybkSroG86fd",
        "outputId": "af7709cb-3496-4cf2-ef3a-969ccaf81db4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 3s 280ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ALEXNET"
      ],
      "metadata": {
        "id": "E5oBEU9PvdP3"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11),\\\n",
        " strides=(4,4), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation before passing it to the next layer\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
        "model.add(Activation('relu'))\n",
        "# Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Passing it to a dense layer\n",
        "model.add(Flatten())\n",
        "# 1st Dense Layer\n",
        "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 2nd Dense Layer\n",
        "model.add(Dense(4096))\n",
        "model.add(Activation('relu'))\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 3rd Dense Layer\n",
        "model.add(Dense(1000))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Add Dropout\n",
        "model.add(Dropout(0.4))\n",
        "# Batch Normalisation\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(4))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "0dryySTEvdTP",
        "outputId": "172d66be-25b1-4bd4-cf54-97a30020088d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 54, 54, 96)        34944     \n",
            "                                                                 \n",
            " activation (Activation)     (None, 54, 54, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 27, 27, 96)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 27, 27, 96)        384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 17, 17, 256)       2973952   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 17, 17, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 6, 6, 384)         885120    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6, 6, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 6, 6, 384)         1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4, 4, 384)         0         \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 4, 4, 384)         1536      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 2, 2, 256)         884992    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 1, 1, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 1, 1, 256)         1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 4096)              1052672   \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 4096)              16781312  \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 4096)              0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 4096)              16384     \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1000)              4097000   \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 1000)              0         \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 1000)              0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 1000)              4000      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 4)                 4004      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28083756 (107.13 MB)\n",
            "Trainable params: 28062620 (107.05 MB)\n",
            "Non-trainable params: 21136 (82.56 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "opt1 = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = opt,\n",
        "             metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "BxK8rc0D0Gg6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "test = test_generator\n",
        "score = model.evaluate(test, verbose = 1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "ns57M3pa0GnB",
        "outputId": "b417d699-9daf-476a-b583-a5e182d96195",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 71s 476ms/step - loss: 2.0854 - accuracy: 0.4584 - val_loss: 1669.7186 - val_accuracy: 0.1806\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 14s 695ms/step - loss: 1.4975 - accuracy: 0.4780 - val_loss: 226.8793 - val_accuracy: 0.1806\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 12s 584ms/step - loss: 1.2074 - accuracy: 0.5334 - val_loss: 34.7279 - val_accuracy: 0.1111\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 10s 501ms/step - loss: 1.2081 - accuracy: 0.5090 - val_loss: 24.8095 - val_accuracy: 0.1806\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 12s 609ms/step - loss: 1.0735 - accuracy: 0.5498 - val_loss: 22.8586 - val_accuracy: 0.1944\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 12s 603ms/step - loss: 1.1016 - accuracy: 0.5449 - val_loss: 4.4640 - val_accuracy: 0.3056\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 1.0314 - accuracy: 0.5612 - val_loss: 6.5096 - val_accuracy: 0.3056\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 1.0662 - accuracy: 0.5383 - val_loss: 3.7615 - val_accuracy: 0.1389\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 12s 596ms/step - loss: 1.0303 - accuracy: 0.5579 - val_loss: 2.0838 - val_accuracy: 0.4861\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 12s 593ms/step - loss: 1.0292 - accuracy: 0.5498 - val_loss: 1.6002 - val_accuracy: 0.4722\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 12s 573ms/step - loss: 1.0314 - accuracy: 0.5840 - val_loss: 1.6305 - val_accuracy: 0.5000\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 12s 600ms/step - loss: 1.0132 - accuracy: 0.5644 - val_loss: 1.4321 - val_accuracy: 0.4167\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 11s 521ms/step - loss: 1.0322 - accuracy: 0.5546 - val_loss: 1.0030 - val_accuracy: 0.5694\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 12s 598ms/step - loss: 1.0710 - accuracy: 0.5269 - val_loss: 0.9722 - val_accuracy: 0.5833\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 12s 589ms/step - loss: 0.9811 - accuracy: 0.5579 - val_loss: 1.0130 - val_accuracy: 0.5139\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 12s 606ms/step - loss: 1.0411 - accuracy: 0.5237 - val_loss: 1.3804 - val_accuracy: 0.4028\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 12s 586ms/step - loss: 0.9799 - accuracy: 0.5465 - val_loss: 1.2384 - val_accuracy: 0.4722\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 11s 564ms/step - loss: 0.9206 - accuracy: 0.6003 - val_loss: 1.0035 - val_accuracy: 0.5278\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 12s 594ms/step - loss: 0.9499 - accuracy: 0.5498 - val_loss: 1.3343 - val_accuracy: 0.3194\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 12s 589ms/step - loss: 0.9555 - accuracy: 0.5628 - val_loss: 1.1372 - val_accuracy: 0.4583\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 0.9186 - accuracy: 0.5726 - val_loss: 1.7176 - val_accuracy: 0.3750\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 0.9729 - accuracy: 0.5873 - val_loss: 1.2366 - val_accuracy: 0.5278\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 1.0023 - accuracy: 0.5628 - val_loss: 1.3661 - val_accuracy: 0.5694\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 12s 591ms/step - loss: 1.1106 - accuracy: 0.4943 - val_loss: 1.2943 - val_accuracy: 0.5417\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 12s 585ms/step - loss: 1.0094 - accuracy: 0.5351 - val_loss: 1.6903 - val_accuracy: 0.4444\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 11s 544ms/step - loss: 1.0060 - accuracy: 0.5563 - val_loss: 1.6640 - val_accuracy: 0.5556\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 11s 525ms/step - loss: 1.0400 - accuracy: 0.5612 - val_loss: 1.3491 - val_accuracy: 0.4167\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 12s 594ms/step - loss: 0.9102 - accuracy: 0.5938 - val_loss: 1.5341 - val_accuracy: 0.4583\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 12s 601ms/step - loss: 0.9852 - accuracy: 0.5726 - val_loss: 1.0158 - val_accuracy: 0.5694\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 1.0390 - accuracy: 0.5628 - val_loss: 6.3052 - val_accuracy: 0.2083\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 12s 606ms/step - loss: 1.1728 - accuracy: 0.4976 - val_loss: 5.5395 - val_accuracy: 0.4028\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 14s 708ms/step - loss: 1.0713 - accuracy: 0.5612 - val_loss: 2.0783 - val_accuracy: 0.3472\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 12s 601ms/step - loss: 1.0459 - accuracy: 0.5498 - val_loss: 1.4730 - val_accuracy: 0.4722\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 1.0140 - accuracy: 0.5579 - val_loss: 1.1111 - val_accuracy: 0.5972\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 1.0252 - accuracy: 0.5579 - val_loss: 1.1760 - val_accuracy: 0.5972\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 11s 513ms/step - loss: 0.9578 - accuracy: 0.5856 - val_loss: 1.0887 - val_accuracy: 0.5556\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 12s 620ms/step - loss: 0.9527 - accuracy: 0.5840 - val_loss: 1.3069 - val_accuracy: 0.4861\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 12s 609ms/step - loss: 0.9082 - accuracy: 0.6232 - val_loss: 1.1842 - val_accuracy: 0.5000\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 12s 599ms/step - loss: 0.9911 - accuracy: 0.5954 - val_loss: 1.3183 - val_accuracy: 0.4722\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 10s 506ms/step - loss: 0.9978 - accuracy: 0.5644 - val_loss: 1.8458 - val_accuracy: 0.4167\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 12s 565ms/step - loss: 0.9266 - accuracy: 0.5808 - val_loss: 0.9272 - val_accuracy: 0.5833\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 12s 587ms/step - loss: 0.9624 - accuracy: 0.5856 - val_loss: 1.2281 - val_accuracy: 0.3889\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 12s 590ms/step - loss: 0.8748 - accuracy: 0.6264 - val_loss: 1.1036 - val_accuracy: 0.5833\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 12s 610ms/step - loss: 0.9021 - accuracy: 0.6020 - val_loss: 0.9571 - val_accuracy: 0.5694\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 12s 603ms/step - loss: 0.8852 - accuracy: 0.6052 - val_loss: 0.9389 - val_accuracy: 0.5972\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 12s 596ms/step - loss: 0.8352 - accuracy: 0.6330 - val_loss: 1.2170 - val_accuracy: 0.5278\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 12s 609ms/step - loss: 0.8645 - accuracy: 0.6444 - val_loss: 1.4140 - val_accuracy: 0.3194\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.8583 - accuracy: 0.6232 - val_loss: 1.0938 - val_accuracy: 0.5000\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 13s 634ms/step - loss: 0.8962 - accuracy: 0.6052 - val_loss: 1.2953 - val_accuracy: 0.5417\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 12s 619ms/step - loss: 0.8779 - accuracy: 0.6117 - val_loss: 1.1586 - val_accuracy: 0.5694\n",
            "10/10 [==============================] - 3s 276ms/step - loss: 0.8022 - accuracy: 0.6635\n",
            "Test loss: 0.8021857142448425\n",
            "Test accuracy: 0.6634920835494995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = len(test_generator)\n",
        "num_classes = len(test_generator.class_indices)\n",
        "\n",
        "predicted_probabilities_AlexNet = model.predict(test_generator, steps=num_test_samples)"
      ],
      "metadata": {
        "id": "emoCYEmX0Gsf",
        "outputId": "e697f071-07f0-4b73-f732-6638e073c00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 219ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DX-z5a7Z0G4u"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_v3 = tf.keras.applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "metadata": {
        "id": "ZoVjdxcv0G7k",
        "outputId": "79a12c9e-bf28-44ca-b374-44fa2b7a9fa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87910968/87910968 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in inception_v3.layers[: -15]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "_C_ah7AZ2ebw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = inception_v3.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "x = Dense(units=512, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "output = Dense(units=4, activation='softmax')(x)\n",
        "model = Model(inception_v3.input, output)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "_LhSFOte0G-r",
        "outputId": "35e4399b-0341-4218-a309-2c4be5ed27ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 111, 111, 32)         864       ['input_3[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 111, 111, 32)         96        ['conv2d_5[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 111, 111, 32)         0         ['batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 109, 109, 32)         9216      ['activation_9[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 109, 109, 32)         96        ['conv2d_6[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 109, 109, 32)         0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 109, 109, 64)         18432     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 109, 109, 64)         192       ['conv2d_7[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 109, 109, 64)         0         ['batch_normalization_13[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPoolin  (None, 54, 54, 64)           0         ['activation_11[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 54, 54, 80)           5120      ['max_pooling2d_6[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_14 (Ba  (None, 54, 54, 80)           240       ['conv2d_8[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 54, 54, 80)           0         ['batch_normalization_14[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 52, 52, 192)          138240    ['activation_12[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_15 (Ba  (None, 52, 52, 192)          576       ['conv2d_9[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 52, 52, 192)          0         ['batch_normalization_15[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPoolin  (None, 25, 25, 192)          0         ['activation_13[0][0]']       \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 25, 25, 64)           12288     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " batch_normalization_19 (Ba  (None, 25, 25, 64)           192       ['conv2d_13[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_17 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_19[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 25, 25, 48)           9216      ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 25, 25, 96)           55296     ['activation_17[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_17 (Ba  (None, 25, 25, 48)           144       ['conv2d_11[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_20 (Ba  (None, 25, 25, 96)           288       ['conv2d_14[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)  (None, 25, 25, 48)           0         ['batch_normalization_17[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_18 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_20[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d (Average  (None, 25, 25, 192)          0         ['max_pooling2d_7[0][0]']     \n",
            " Pooling2D)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 25, 25, 64)           12288     ['max_pooling2d_7[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 25, 25, 64)           76800     ['activation_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 25, 25, 96)           82944     ['activation_18[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 25, 25, 32)           6144      ['average_pooling2d[0][0]']   \n",
            "                                                                                                  \n",
            " batch_normalization_16 (Ba  (None, 25, 25, 64)           192       ['conv2d_10[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_18 (Ba  (None, 25, 25, 64)           192       ['conv2d_12[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_21 (Ba  (None, 25, 25, 96)           288       ['conv2d_15[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_22 (Ba  (None, 25, 25, 32)           96        ['conv2d_16[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_16[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_16 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_18[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_19 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_21[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_20 (Activation)  (None, 25, 25, 32)           0         ['batch_normalization_22[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 25, 25, 256)          0         ['activation_14[0][0]',       \n",
            "                                                                     'activation_16[0][0]',       \n",
            "                                                                     'activation_19[0][0]',       \n",
            "                                                                     'activation_20[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 25, 25, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_26 (Ba  (None, 25, 25, 64)           192       ['conv2d_20[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_24 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_26[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 25, 25, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)          (None, 25, 25, 96)           55296     ['activation_24[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_24 (Ba  (None, 25, 25, 48)           144       ['conv2d_18[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_27 (Ba  (None, 25, 25, 96)           288       ['conv2d_21[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_22 (Activation)  (None, 25, 25, 48)           0         ['batch_normalization_24[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_25 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_27[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (Avera  (None, 25, 25, 256)          0         ['mixed0[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 25, 25, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 25, 25, 64)           76800     ['activation_22[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)          (None, 25, 25, 96)           82944     ['activation_25[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)          (None, 25, 25, 64)           16384     ['average_pooling2d_1[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_23 (Ba  (None, 25, 25, 64)           192       ['conv2d_17[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_25 (Ba  (None, 25, 25, 64)           192       ['conv2d_19[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_28 (Ba  (None, 25, 25, 96)           288       ['conv2d_22[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_29 (Ba  (None, 25, 25, 64)           192       ['conv2d_23[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_21 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_23[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_23 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_25[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_26 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_28[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_27 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_29[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 25, 25, 288)          0         ['activation_21[0][0]',       \n",
            "                                                                     'activation_23[0][0]',       \n",
            "                                                                     'activation_26[0][0]',       \n",
            "                                                                     'activation_27[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)          (None, 25, 25, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_33 (Ba  (None, 25, 25, 64)           192       ['conv2d_27[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_31 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_33[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)          (None, 25, 25, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)          (None, 25, 25, 96)           55296     ['activation_31[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_31 (Ba  (None, 25, 25, 48)           144       ['conv2d_25[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_34 (Ba  (None, 25, 25, 96)           288       ['conv2d_28[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_29 (Activation)  (None, 25, 25, 48)           0         ['batch_normalization_31[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_32 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_34[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (Avera  (None, 25, 25, 288)          0         ['mixed1[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)          (None, 25, 25, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)          (None, 25, 25, 64)           76800     ['activation_29[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)          (None, 25, 25, 96)           82944     ['activation_32[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)          (None, 25, 25, 64)           18432     ['average_pooling2d_2[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_30 (Ba  (None, 25, 25, 64)           192       ['conv2d_24[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_32 (Ba  (None, 25, 25, 64)           192       ['conv2d_26[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_35 (Ba  (None, 25, 25, 96)           288       ['conv2d_29[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_36 (Ba  (None, 25, 25, 64)           192       ['conv2d_30[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_28 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_30[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_30 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_32[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_33 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_35[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_34 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_36[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 25, 25, 288)          0         ['activation_28[0][0]',       \n",
            "                                                                     'activation_30[0][0]',       \n",
            "                                                                     'activation_33[0][0]',       \n",
            "                                                                     'activation_34[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)          (None, 25, 25, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_38 (Ba  (None, 25, 25, 64)           192       ['conv2d_32[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_36 (Activation)  (None, 25, 25, 64)           0         ['batch_normalization_38[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)          (None, 25, 25, 96)           55296     ['activation_36[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_39 (Ba  (None, 25, 25, 96)           288       ['conv2d_33[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_37 (Activation)  (None, 25, 25, 96)           0         ['batch_normalization_39[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)          (None, 12, 12, 384)          995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)          (None, 12, 12, 96)           82944     ['activation_37[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_37 (Ba  (None, 12, 12, 384)          1152      ['conv2d_31[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_40 (Ba  (None, 12, 12, 96)           288       ['conv2d_34[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_35 (Activation)  (None, 12, 12, 384)          0         ['batch_normalization_37[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_38 (Activation)  (None, 12, 12, 96)           0         ['batch_normalization_40[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPoolin  (None, 12, 12, 288)          0         ['mixed2[0][0]']              \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 12, 12, 768)          0         ['activation_35[0][0]',       \n",
            "                                                                     'activation_38[0][0]',       \n",
            "                                                                     'max_pooling2d_8[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)          (None, 12, 12, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_45 (Ba  (None, 12, 12, 128)          384       ['conv2d_39[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_43 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_45[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)          (None, 12, 12, 128)          114688    ['activation_43[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_46 (Ba  (None, 12, 12, 128)          384       ['conv2d_40[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_44 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_46[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)          (None, 12, 12, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)          (None, 12, 12, 128)          114688    ['activation_44[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_42 (Ba  (None, 12, 12, 128)          384       ['conv2d_36[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_47 (Ba  (None, 12, 12, 128)          384       ['conv2d_41[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_40 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_42[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_45 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_47[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)          (None, 12, 12, 128)          114688    ['activation_40[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)          (None, 12, 12, 128)          114688    ['activation_45[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_43 (Ba  (None, 12, 12, 128)          384       ['conv2d_37[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_48 (Ba  (None, 12, 12, 128)          384       ['conv2d_42[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_41 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_43[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_46 (Activation)  (None, 12, 12, 128)          0         ['batch_normalization_48[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (Avera  (None, 12, 12, 768)          0         ['mixed3[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)          (None, 12, 12, 192)          172032    ['activation_41[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)          (None, 12, 12, 192)          172032    ['activation_46[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)          (None, 12, 12, 192)          147456    ['average_pooling2d_3[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_41 (Ba  (None, 12, 12, 192)          576       ['conv2d_35[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_44 (Ba  (None, 12, 12, 192)          576       ['conv2d_38[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_49 (Ba  (None, 12, 12, 192)          576       ['conv2d_43[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_50 (Ba  (None, 12, 12, 192)          576       ['conv2d_44[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_39 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_41[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_42 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_44[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_47 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_49[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_48 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_50[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 12, 12, 768)          0         ['activation_39[0][0]',       \n",
            "                                                                     'activation_42[0][0]',       \n",
            "                                                                     'activation_47[0][0]',       \n",
            "                                                                     'activation_48[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)          (None, 12, 12, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 12, 12, 160)          480       ['conv2d_49[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_53 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_53[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 12, 12, 160)          480       ['conv2d_50[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_54 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)          (None, 12, 12, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_54[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_52 (Ba  (None, 12, 12, 160)          480       ['conv2d_46[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 12, 12, 160)          480       ['conv2d_51[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_50 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_52[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_55 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_50[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_55[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_53 (Ba  (None, 12, 12, 160)          480       ['conv2d_47[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 12, 12, 160)          480       ['conv2d_52[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_51 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_53[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_56 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (Avera  (None, 12, 12, 768)          0         ['mixed4[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)          (None, 12, 12, 192)          215040    ['activation_51[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)          (None, 12, 12, 192)          215040    ['activation_56[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)          (None, 12, 12, 192)          147456    ['average_pooling2d_4[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_51 (Ba  (None, 12, 12, 192)          576       ['conv2d_45[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 12, 12, 192)          576       ['conv2d_48[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 12, 12, 192)          576       ['conv2d_53[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 12, 12, 192)          576       ['conv2d_54[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_49 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_51[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_52 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_57 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_58 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 12, 12, 768)          0         ['activation_49[0][0]',       \n",
            "                                                                     'activation_52[0][0]',       \n",
            "                                                                     'activation_57[0][0]',       \n",
            "                                                                     'activation_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)          (None, 12, 12, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_65 (Ba  (None, 12, 12, 160)          480       ['conv2d_59[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_63 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_65[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_63[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_66 (Ba  (None, 12, 12, 160)          480       ['conv2d_60[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_64 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_66[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)          (None, 12, 12, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_64[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 12, 12, 160)          480       ['conv2d_56[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_67 (Ba  (None, 12, 12, 160)          480       ['conv2d_61[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_60 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_65 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_67[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_60[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)          (None, 12, 12, 160)          179200    ['activation_65[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_63 (Ba  (None, 12, 12, 160)          480       ['conv2d_57[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_68 (Ba  (None, 12, 12, 160)          480       ['conv2d_62[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_61 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_63[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_66 (Activation)  (None, 12, 12, 160)          0         ['batch_normalization_68[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (Avera  (None, 12, 12, 768)          0         ['mixed5[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)          (None, 12, 12, 192)          215040    ['activation_61[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)          (None, 12, 12, 192)          215040    ['activation_66[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)          (None, 12, 12, 192)          147456    ['average_pooling2d_5[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 12, 12, 192)          576       ['conv2d_55[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_64 (Ba  (None, 12, 12, 192)          576       ['conv2d_58[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_69 (Ba  (None, 12, 12, 192)          576       ['conv2d_63[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_70 (Ba  (None, 12, 12, 192)          576       ['conv2d_64[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_59 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_62 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_64[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_67 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_69[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_68 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_70[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 12, 12, 768)          0         ['activation_59[0][0]',       \n",
            "                                                                     'activation_62[0][0]',       \n",
            "                                                                     'activation_67[0][0]',       \n",
            "                                                                     'activation_68[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_75 (Ba  (None, 12, 12, 192)          576       ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_73 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_75[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_73[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_76 (Ba  (None, 12, 12, 192)          576       ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_74 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_76[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_74[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_72 (Ba  (None, 12, 12, 192)          576       ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_77 (Ba  (None, 12, 12, 192)          576       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_70 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_72[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_75 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_77[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_70[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_75[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_73 (Ba  (None, 12, 12, 192)          576       ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_78 (Ba  (None, 12, 12, 192)          576       ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_71 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_73[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_76 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_78[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 12, 12, 768)          0         ['mixed6[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_71[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_76[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 12, 12, 192)          147456    ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_71 (Ba  (None, 12, 12, 192)          576       ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_74 (Ba  (None, 12, 12, 192)          576       ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_79 (Ba  (None, 12, 12, 192)          576       ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_80 (Ba  (None, 12, 12, 192)          576       ['conv2d_74[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_69 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_71[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_72 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_74[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_77 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_79[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_78 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_80[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 12, 12, 768)          0         ['activation_69[0][0]',       \n",
            "                                                                     'activation_72[0][0]',       \n",
            "                                                                     'activation_77[0][0]',       \n",
            "                                                                     'activation_78[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_83 (Ba  (None, 12, 12, 192)          576       ['conv2d_77[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_81 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_83[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_81[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_84 (Ba  (None, 12, 12, 192)          576       ['conv2d_78[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_82 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_84[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)          (None, 12, 12, 192)          147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)          (None, 12, 12, 192)          258048    ['activation_82[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_81 (Ba  (None, 12, 12, 192)          576       ['conv2d_75[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_85 (Ba  (None, 12, 12, 192)          576       ['conv2d_79[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_79 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_81[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_83 (Activation)  (None, 12, 12, 192)          0         ['batch_normalization_85[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)          (None, 5, 5, 320)            552960    ['activation_79[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)          (None, 5, 5, 192)            331776    ['activation_83[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_82 (Ba  (None, 5, 5, 320)            960       ['conv2d_76[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_86 (Ba  (None, 5, 5, 192)            576       ['conv2d_80[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_80 (Activation)  (None, 5, 5, 320)            0         ['batch_normalization_82[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_84 (Activation)  (None, 5, 5, 192)            0         ['batch_normalization_86[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " max_pooling2d_9 (MaxPoolin  (None, 5, 5, 768)            0         ['mixed7[0][0]']              \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 5, 5, 1280)           0         ['activation_80[0][0]',       \n",
            "                                                                     'activation_84[0][0]',       \n",
            "                                                                     'max_pooling2d_9[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)          (None, 5, 5, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_91 (Ba  (None, 5, 5, 448)            1344      ['conv2d_85[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_89 (Activation)  (None, 5, 5, 448)            0         ['batch_normalization_91[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)          (None, 5, 5, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)          (None, 5, 5, 384)            1548288   ['activation_89[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_88 (Ba  (None, 5, 5, 384)            1152      ['conv2d_82[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_92 (Ba  (None, 5, 5, 384)            1152      ['conv2d_86[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_86 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_88[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_90 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_92[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_86[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_90[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (Avera  (None, 5, 5, 1280)           0         ['mixed8[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)          (None, 5, 5, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_89 (Ba  (None, 5, 5, 384)            1152      ['conv2d_83[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_90 (Ba  (None, 5, 5, 384)            1152      ['conv2d_84[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_93 (Ba  (None, 5, 5, 384)            1152      ['conv2d_87[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_94 (Ba  (None, 5, 5, 384)            1152      ['conv2d_88[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)          (None, 5, 5, 192)            245760    ['average_pooling2d_7[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_87 (Ba  (None, 5, 5, 320)            960       ['conv2d_81[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_87 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_89[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_88 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_90[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_91 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_93[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_92 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_94[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_95 (Ba  (None, 5, 5, 192)            576       ['conv2d_89[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_85 (Activation)  (None, 5, 5, 320)            0         ['batch_normalization_87[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 5, 5, 768)            0         ['activation_87[0][0]',       \n",
            "                                                                     'activation_88[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 5, 5, 768)            0         ['activation_91[0][0]',       \n",
            "                                                                     'activation_92[0][0]']       \n",
            "                                                                                                  \n",
            " activation_93 (Activation)  (None, 5, 5, 192)            0         ['batch_normalization_95[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 5, 5, 2048)           0         ['activation_85[0][0]',       \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate[0][0]',         \n",
            "                                                                     'activation_93[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_94 (Conv2D)          (None, 5, 5, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_100 (B  (None, 5, 5, 448)            1344      ['conv2d_94[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_98 (Activation)  (None, 5, 5, 448)            0         ['batch_normalization_100[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)          (None, 5, 5, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_95 (Conv2D)          (None, 5, 5, 384)            1548288   ['activation_98[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_97 (Ba  (None, 5, 5, 384)            1152      ['conv2d_91[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_101 (B  (None, 5, 5, 384)            1152      ['conv2d_95[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_95 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_97[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_99 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_101[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_95[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_95[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_96 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_99[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_97 (Conv2D)          (None, 5, 5, 384)            442368    ['activation_99[0][0]']       \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (Avera  (None, 5, 5, 2048)           0         ['mixed9[0][0]']              \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)          (None, 5, 5, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_98 (Ba  (None, 5, 5, 384)            1152      ['conv2d_92[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_99 (Ba  (None, 5, 5, 384)            1152      ['conv2d_93[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_102 (B  (None, 5, 5, 384)            1152      ['conv2d_96[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_103 (B  (None, 5, 5, 384)            1152      ['conv2d_97[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_98 (Conv2D)          (None, 5, 5, 192)            393216    ['average_pooling2d_8[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_96 (Ba  (None, 5, 5, 320)            960       ['conv2d_90[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_96 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_98[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_97 (Activation)  (None, 5, 5, 384)            0         ['batch_normalization_99[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " activation_100 (Activation  (None, 5, 5, 384)            0         ['batch_normalization_102[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_101 (Activation  (None, 5, 5, 384)            0         ['batch_normalization_103[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_104 (B  (None, 5, 5, 192)            576       ['conv2d_98[0][0]']           \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_94 (Activation)  (None, 5, 5, 320)            0         ['batch_normalization_96[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 5, 5, 768)            0         ['activation_96[0][0]',       \n",
            "                                                                     'activation_97[0][0]']       \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 5, 5, 768)            0         ['activation_100[0][0]',      \n",
            " )                                                                   'activation_101[0][0]']      \n",
            "                                                                                                  \n",
            " activation_102 (Activation  (None, 5, 5, 192)            0         ['batch_normalization_104[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 5, 5, 2048)           0         ['activation_94[0][0]',       \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_1[0][0]',       \n",
            "                                                                     'activation_102[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 51200)                0         ['mixed10[0][0]']             \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 512)                  2621491   ['flatten_4[0][0]']           \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 512)                  0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 512)                  262656    ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 512)                  0         ['dense_17[0][0]']            \n",
            "                                                                                                  \n",
            " dense_18 (Dense)            (None, 4)                    2052      ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 48282404 (184.18 MB)\n",
            "Trainable params: 26874500 (102.52 MB)\n",
            "Non-trainable params: 21407904 (81.66 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "opt1 = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = opt,\n",
        "             metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "2ivl2dOe0HBz"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")\n",
        "test = test_generator\n",
        "score = model.evaluate(test, verbose = 1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "id": "I8oqPXhm3A7M",
        "outputId": "83771bf7-0915-4d4a-f350-48ef72e0b7d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 23s 638ms/step - loss: 46.5467 - accuracy: 0.3377 - val_loss: 15.7559 - val_accuracy: 0.4722\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 11s 529ms/step - loss: 17.3311 - accuracy: 0.4192 - val_loss: 4.9546 - val_accuracy: 0.4861\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 12s 619ms/step - loss: 7.3039 - accuracy: 0.3964 - val_loss: 2.5117 - val_accuracy: 0.4444\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 12s 620ms/step - loss: 3.4427 - accuracy: 0.4405 - val_loss: 1.7002 - val_accuracy: 0.5278\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 11s 526ms/step - loss: 2.1134 - accuracy: 0.3491 - val_loss: 1.2743 - val_accuracy: 0.4167\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 13s 611ms/step - loss: 1.5010 - accuracy: 0.4062 - val_loss: 1.2333 - val_accuracy: 0.5278\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 13s 639ms/step - loss: 1.4119 - accuracy: 0.4307 - val_loss: 1.2371 - val_accuracy: 0.5000\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 13s 626ms/step - loss: 1.2977 - accuracy: 0.4454 - val_loss: 1.2076 - val_accuracy: 0.5000\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 12s 606ms/step - loss: 1.3478 - accuracy: 0.4405 - val_loss: 1.2190 - val_accuracy: 0.4861\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 13s 628ms/step - loss: 1.2366 - accuracy: 0.4715 - val_loss: 1.1982 - val_accuracy: 0.4583\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 13s 630ms/step - loss: 1.3114 - accuracy: 0.4551 - val_loss: 1.1332 - val_accuracy: 0.5417\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 12s 581ms/step - loss: 1.3318 - accuracy: 0.4763 - val_loss: 1.1602 - val_accuracy: 0.5278\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 11s 544ms/step - loss: 1.3565 - accuracy: 0.5041 - val_loss: 1.1216 - val_accuracy: 0.5278\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 13s 627ms/step - loss: 1.2651 - accuracy: 0.4878 - val_loss: 1.1803 - val_accuracy: 0.5556\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 14s 724ms/step - loss: 1.3176 - accuracy: 0.4796 - val_loss: 1.1749 - val_accuracy: 0.4722\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 12s 621ms/step - loss: 1.3003 - accuracy: 0.4763 - val_loss: 1.2526 - val_accuracy: 0.4028\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 12s 595ms/step - loss: 1.2665 - accuracy: 0.4551 - val_loss: 1.2477 - val_accuracy: 0.4167\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 12s 617ms/step - loss: 1.2818 - accuracy: 0.4192 - val_loss: 1.3249 - val_accuracy: 0.3889\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 12s 618ms/step - loss: 1.2733 - accuracy: 0.4600 - val_loss: 1.2612 - val_accuracy: 0.4167\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 12s 616ms/step - loss: 1.2644 - accuracy: 0.4698 - val_loss: 1.1756 - val_accuracy: 0.4722\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 12s 572ms/step - loss: 1.1619 - accuracy: 0.5204 - val_loss: 1.1109 - val_accuracy: 0.5139\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 12s 626ms/step - loss: 1.2909 - accuracy: 0.5122 - val_loss: 1.1689 - val_accuracy: 0.4306\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 12s 618ms/step - loss: 1.3009 - accuracy: 0.4910 - val_loss: 1.2395 - val_accuracy: 0.4028\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 12s 605ms/step - loss: 1.2246 - accuracy: 0.4894 - val_loss: 1.2016 - val_accuracy: 0.4444\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 11s 539ms/step - loss: 1.2539 - accuracy: 0.4894 - val_loss: 1.1870 - val_accuracy: 0.4583\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 12s 627ms/step - loss: 1.2045 - accuracy: 0.4812 - val_loss: 1.1523 - val_accuracy: 0.4583\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 12s 582ms/step - loss: 1.2200 - accuracy: 0.4763 - val_loss: 1.2365 - val_accuracy: 0.4028\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 11s 537ms/step - loss: 1.2114 - accuracy: 0.4535 - val_loss: 1.0921 - val_accuracy: 0.4861\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 12s 605ms/step - loss: 1.1955 - accuracy: 0.5073 - val_loss: 1.0913 - val_accuracy: 0.4861\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 12s 621ms/step - loss: 1.2405 - accuracy: 0.5057 - val_loss: 1.2546 - val_accuracy: 0.4861\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 13s 629ms/step - loss: 1.2321 - accuracy: 0.4551 - val_loss: 1.0872 - val_accuracy: 0.4861\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 1.2724 - accuracy: 0.4535 - val_loss: 1.1912 - val_accuracy: 0.4167\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 1.2997 - accuracy: 0.4388 - val_loss: 1.1121 - val_accuracy: 0.4861\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 14s 713ms/step - loss: 1.3804 - accuracy: 0.3980 - val_loss: 1.0837 - val_accuracy: 0.4722\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 13s 629ms/step - loss: 1.2055 - accuracy: 0.4274 - val_loss: 1.1491 - val_accuracy: 0.4722\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 13s 640ms/step - loss: 1.2001 - accuracy: 0.4845 - val_loss: 1.2096 - val_accuracy: 0.4583\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 12s 573ms/step - loss: 1.3413 - accuracy: 0.4649 - val_loss: 1.2506 - val_accuracy: 0.4028\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 13s 634ms/step - loss: 1.2732 - accuracy: 0.4111 - val_loss: 1.1462 - val_accuracy: 0.4583\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 1.2669 - accuracy: 0.4421 - val_loss: 1.0586 - val_accuracy: 0.5278\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 1.2348 - accuracy: 0.4568 - val_loss: 1.1228 - val_accuracy: 0.4861\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 13s 641ms/step - loss: 1.2154 - accuracy: 0.4584 - val_loss: 1.1114 - val_accuracy: 0.5000\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 13s 644ms/step - loss: 1.1604 - accuracy: 0.4682 - val_loss: 1.1310 - val_accuracy: 0.4722\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 13s 636ms/step - loss: 1.2054 - accuracy: 0.4633 - val_loss: 1.0372 - val_accuracy: 0.4444\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 13s 639ms/step - loss: 1.3044 - accuracy: 0.4241 - val_loss: 1.0588 - val_accuracy: 0.4722\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 13s 637ms/step - loss: 1.2979 - accuracy: 0.4062 - val_loss: 1.1777 - val_accuracy: 0.4444\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 1.2811 - accuracy: 0.4682 - val_loss: 1.0650 - val_accuracy: 0.4861\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 13s 632ms/step - loss: 1.1740 - accuracy: 0.5155 - val_loss: 0.9999 - val_accuracy: 0.5000\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 12s 566ms/step - loss: 1.2847 - accuracy: 0.4992 - val_loss: 1.0929 - val_accuracy: 0.4861\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 13s 631ms/step - loss: 1.2342 - accuracy: 0.4649 - val_loss: 1.1295 - val_accuracy: 0.4722\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 1.2434 - accuracy: 0.4078 - val_loss: 1.1854 - val_accuracy: 0.4306\n",
            "10/10 [==============================] - 5s 483ms/step - loss: 1.1465 - accuracy: 0.5079\n",
            "Test loss: 1.1464617252349854\n",
            "Test accuracy: 0.5079365372657776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = len(test_generator)\n",
        "num_classes = len(test_generator.class_indices)\n",
        "\n",
        "predicted_probabilities_inception_v3 = model.predict(test_generator, steps=num_test_samples)"
      ],
      "metadata": {
        "id": "D4Uo3UYA3A-v",
        "outputId": "e1dce15b-969f-4347-f074-26682dbf272f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 233ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelResNet50 = ResNet50(weights = 'imagenet',\n",
        "                     include_top = False,\n",
        "                     input_shape = input_shape)\n",
        "\n",
        "for layer in modelResNet50.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFH_VGVCQHeH",
        "outputId": "a76fdbef-663b-4c92-bab0-f6f0cc794673"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    modelResNet50,\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size = (2,2)),\n",
        "    Dropout(.3),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(512, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(256, activation = 'relu'),\n",
        "    Dropout(.3),\n",
        "    Dense(num_class, activation = 'softmax')\n",
        "])\n",
        "\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btkcEpqIQHkG",
        "outputId": "27cde00f-bd01-48eb-98d2-7c46aa23865c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " batch_normalization_105 (B  (None, 7, 7, 2048)        8192      \n",
            " atchNormalization)                                              \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPooli  (None, 3, 3, 2048)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 3, 3, 2048)        0         \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 18432)             0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 1024)              18875392  \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_20 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43128452 (164.52 MB)\n",
            "Trainable params: 19536644 (74.53 MB)\n",
            "Non-trainable params: 23591808 (90.00 MB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "opt1 = tf.keras.optimizers.RMSprop(learning_rate = 0.001)\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "             optimizer = opt,\n",
        "             metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "f6Ff4Tv_QoJx"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=epochs,\n",
        "    class_weight=class_weights,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8r-YUuznQHmx",
        "outputId": "0d64ac72-5098-4e2b-ef64-cf3db9253011"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 26s 1s/step - loss: 4.4462 - accuracy: 0.4192 - val_loss: 3.6642 - val_accuracy: 0.4722\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 14s 689ms/step - loss: 2.7088 - accuracy: 0.5269 - val_loss: 1.4525 - val_accuracy: 0.3750\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 1.9518 - accuracy: 0.5090 - val_loss: 1.1467 - val_accuracy: 0.4444\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 13s 650ms/step - loss: 1.4634 - accuracy: 0.5171 - val_loss: 0.9934 - val_accuracy: 0.5417\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 12s 613ms/step - loss: 1.2246 - accuracy: 0.5742 - val_loss: 0.8483 - val_accuracy: 0.5972\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 13s 649ms/step - loss: 0.9935 - accuracy: 0.6134 - val_loss: 0.8652 - val_accuracy: 0.5694\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 0.9703 - accuracy: 0.6346 - val_loss: 0.8325 - val_accuracy: 0.5694\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 13s 628ms/step - loss: 0.9449 - accuracy: 0.6134 - val_loss: 0.7607 - val_accuracy: 0.6806\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 13s 648ms/step - loss: 0.9154 - accuracy: 0.6264 - val_loss: 0.7395 - val_accuracy: 0.6806\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.8057 - accuracy: 0.6574 - val_loss: 0.6891 - val_accuracy: 0.7083\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 13s 650ms/step - loss: 0.6716 - accuracy: 0.6933 - val_loss: 0.6875 - val_accuracy: 0.6806\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.7334 - accuracy: 0.6884 - val_loss: 0.7054 - val_accuracy: 0.6250\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.6442 - accuracy: 0.7162 - val_loss: 0.7207 - val_accuracy: 0.6667\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 0.6251 - accuracy: 0.7357 - val_loss: 0.6848 - val_accuracy: 0.6528\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 13s 657ms/step - loss: 0.5309 - accuracy: 0.7781 - val_loss: 0.5829 - val_accuracy: 0.7222\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.5163 - accuracy: 0.7814 - val_loss: 0.6349 - val_accuracy: 0.7361\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.5887 - accuracy: 0.7488 - val_loss: 0.7118 - val_accuracy: 0.6667\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 0.4882 - accuracy: 0.7912 - val_loss: 0.6044 - val_accuracy: 0.7778\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.5589 - accuracy: 0.7553 - val_loss: 0.5645 - val_accuracy: 0.7639\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 0.5481 - accuracy: 0.7847 - val_loss: 0.5192 - val_accuracy: 0.8056\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 13s 667ms/step - loss: 0.4137 - accuracy: 0.8303 - val_loss: 0.5800 - val_accuracy: 0.7778\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 12s 607ms/step - loss: 0.4982 - accuracy: 0.8124 - val_loss: 0.6432 - val_accuracy: 0.7361\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 13s 608ms/step - loss: 0.4689 - accuracy: 0.7977 - val_loss: 0.6510 - val_accuracy: 0.7361\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 13s 602ms/step - loss: 0.4085 - accuracy: 0.8157 - val_loss: 0.5252 - val_accuracy: 0.8056\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 13s 642ms/step - loss: 0.3623 - accuracy: 0.8662 - val_loss: 0.4513 - val_accuracy: 0.8333\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 13s 661ms/step - loss: 0.4401 - accuracy: 0.8303 - val_loss: 0.5519 - val_accuracy: 0.7917\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 13s 652ms/step - loss: 0.3589 - accuracy: 0.8613 - val_loss: 0.4547 - val_accuracy: 0.8194\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 0.4213 - accuracy: 0.8336 - val_loss: 0.4278 - val_accuracy: 0.8056\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 0.4296 - accuracy: 0.8238 - val_loss: 0.5169 - val_accuracy: 0.8056\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 13s 647ms/step - loss: 0.3675 - accuracy: 0.8646 - val_loss: 0.4875 - val_accuracy: 0.8472\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 13s 658ms/step - loss: 0.3015 - accuracy: 0.8711 - val_loss: 0.4568 - val_accuracy: 0.8472\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 13s 650ms/step - loss: 0.3093 - accuracy: 0.8777 - val_loss: 0.4334 - val_accuracy: 0.8750\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 13s 656ms/step - loss: 0.2690 - accuracy: 0.8907 - val_loss: 0.4756 - val_accuracy: 0.8333\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 13s 613ms/step - loss: 0.3100 - accuracy: 0.8989 - val_loss: 0.5507 - val_accuracy: 0.8056\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 13s 654ms/step - loss: 0.3068 - accuracy: 0.8646 - val_loss: 0.5763 - val_accuracy: 0.7778\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 13s 649ms/step - loss: 0.2770 - accuracy: 0.8874 - val_loss: 0.4212 - val_accuracy: 0.8611\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 13s 681ms/step - loss: 0.2902 - accuracy: 0.8793 - val_loss: 0.3594 - val_accuracy: 0.8889\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 0.2572 - accuracy: 0.9070 - val_loss: 0.4620 - val_accuracy: 0.8194\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 13s 659ms/step - loss: 0.3797 - accuracy: 0.8646 - val_loss: 0.3908 - val_accuracy: 0.8611\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 13s 655ms/step - loss: 0.3114 - accuracy: 0.8907 - val_loss: 0.4717 - val_accuracy: 0.8611\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.2997 - accuracy: 0.8662 - val_loss: 0.4669 - val_accuracy: 0.9028\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 13s 652ms/step - loss: 0.2806 - accuracy: 0.9005 - val_loss: 0.6176 - val_accuracy: 0.7778\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 13s 651ms/step - loss: 0.3006 - accuracy: 0.8940 - val_loss: 0.4691 - val_accuracy: 0.8611\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 13s 653ms/step - loss: 0.2728 - accuracy: 0.9021 - val_loss: 0.4259 - val_accuracy: 0.8750\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 12s 591ms/step - loss: 0.2138 - accuracy: 0.9152 - val_loss: 0.5571 - val_accuracy: 0.8333\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 12s 592ms/step - loss: 0.2859 - accuracy: 0.8923 - val_loss: 0.4967 - val_accuracy: 0.8611\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 13s 681ms/step - loss: 0.2464 - accuracy: 0.9054 - val_loss: 0.5560 - val_accuracy: 0.8611\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 13s 656ms/step - loss: 0.3247 - accuracy: 0.8744 - val_loss: 0.4699 - val_accuracy: 0.8056\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 15s 755ms/step - loss: 0.3530 - accuracy: 0.8874 - val_loss: 0.4649 - val_accuracy: 0.8611\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 14s 679ms/step - loss: 0.2867 - accuracy: 0.8858 - val_loss: 0.4108 - val_accuracy: 0.9028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_test_samples = len(test_generator)\n",
        "num_classes = len(test_generator.class_indices)\n",
        "\n",
        "predicted_probabilities_resnet50 = model.predict(test_generator, steps=num_test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFgcsPj-QHpn",
        "outputId": "3612eaf7-f198-4ba4-cd47-19988a2b2f53"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 358ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr=[]\n",
        "for i in range(len(predicted_probabilities_inception_v3)):\n",
        "  temp=[]\n",
        "  for j in range(4):\n",
        "    temp.append((predicted_probabilities_inception_v3[i][j]+predicted_probabilities_vgg16[i][j]+predicted_probabilities_AlexNet[i][j]+predicted_probabilities_resnet50[i][0])/4)\n",
        "  arr.append(temp)"
      ],
      "metadata": {
        "id": "htMINXtrA-k-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = np.argmax(arr, axis=1)\n",
        "\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "report = classification_report(true_labels, predicted_labels)\n",
        "\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNjX6f9cA_YD",
        "outputId": "ab04f841-c056-41fe-afa1-f458e642785f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.88       120\n",
            "           1       0.79      0.98      0.88        51\n",
            "           2       1.00      1.00      1.00        54\n",
            "           3       0.96      0.73      0.83        90\n",
            "\n",
            "    accuracy                           0.89       315\n",
            "   macro avg       0.90      0.91      0.90       315\n",
            "weighted avg       0.90      0.89      0.88       315\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "print(\"\\n\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='Greens', xticklabels = test_c, yticklabels = test_c)\n",
        "plt.xlabel('\\n\\nPredicted Label\\n')\n",
        "plt.ylabel('\\nTrue Label\\n')\n",
        "plt.title('Confusion Matrix\\n\\n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ql5KSDRu3BCU",
        "outputId": "68102996-9f7c-43c2-dfaa-c49b323f1b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Confusion Matrix:\n",
            " [[109   8   0   3]\n",
            " [  1  50   0   0]\n",
            " [  0   0  54   0]\n",
            " [ 19   5   0  66]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0h5W64ra3BK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "52MAnKaw3BNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eZf0qRBI3BPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZtWfAx4v3BSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mc-U2plF3BUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTuuG67a3BXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OCfou5Lq3BZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_r-FzL63BcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "39_RLkb53Bee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PxUhEUmE3Bhw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}